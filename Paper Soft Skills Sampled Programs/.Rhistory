dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 20, scheme = "docfreq")
tokens <- textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("universidad", "profesionales", "perfil", "profesionales", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 20, scheme = "docfreq")
tokens <- textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesionales", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 20, scheme = "docfreq")
tokens <- textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("mastría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesionales", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 20, scheme = "docfreq")
tokens <- textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "mastría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesionales", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 20, scheme = "docfreq")
tokens <- textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "mastría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 20, scheme = "docfreq")
tokens <- textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 20, scheme = "docfreq")
topfeatures(dfm, n = 30, scheme = "docfreq")
topfeatures(dfm, n = 40, scheme = "docfreq")
dfm <- dfm_remove(dfm, c("así", "estudiantes", "área", "así"))
library(quanteda.textstats)
Programs <- textstat_simil(dfm, margin = "documents", method = "jaccard")
ProgramsDF <- data.frame(as.matrix(Programs))
ProgramsDF <- data.frame(jaccard = ProgramsDF[lower.tri(ProgramsDF, diag = FALSE)])
# In fourth place, we applied
# a Gaussian finite mixture model fitted by EM algorithm
library(mclust)
fit <- Mclust(ProgramsDF)
summary(fit)
Classification <- data.frame(fit$classification)
names(Classification)[1] <- "classification"
View(Classification)
View(Programs)
Programs <- textstat_simil(dfm, margin = "documents", method = "jaccard")
ProgramsDF <- data.frame(as.matrix(Programs))
View(ProgramsDF)
View(Classification)
ProgramsDF <- data.frame(jaccard = ProgramsDF[lower.tri(ProgramsDF, diag = FALSE)])
# In fourth place, we applied
# a Gaussian finite mixture model fitted by EM algorithm
library(mclust)
fit <- Mclust(ProgramsDF)
summary(fit)
Classification <- data.frame(fit$classification)
names(Classification)[1] <- "classification"
Programs$Programs$Dim
Programs$Dim
Programs@Dim
Programs@factors
Programs@method
Programs@margin
Programs@Dimnames
View(listado)
View(textos)
setwd("/home/jc/Documents/Paper Soft Skills Sampled Programs")
listado <- data.frame(dir())
library(readtext)
library(tm)
DirSource()
# Get the data directory from readtext
DATA_DIR <- system.file("extdata/", package = "readtext")
textos <- readtext(listado$dir..)
textos$doc_id <- gsub("[^0-9-]", "", textos$doc_id)
library(quanteda)
AllPrograms <- corpus(textos)
source("~/Documents/GitHub/SoftSkillsUniversityPrograms/SampleAnalysis.R")
docvars(AllPrograms, "Programa") <- Muestra$NOMBRE_DEL_PROGRAMA
docvars(AllPrograms, "Program.Level") <- Muestra$`Academic Level`
docvars(AllPrograms, "Institution") <- Muestra$NOMBRE_INSTITUCIÓN
SPEC <- corpus_subset(AllPrograms, Program.Level == "Specialization")
MS <- corpus_subset(AllPrograms, Program.Level == "Masters")
PhD <- corpus_subset(AllPrograms, Program.Level == "Doctorate")
spanishstopwords <- c("egresado", "programa", "programas", "crédito", stopwords("spanish"))
View(Muestra)
textos$Sector <- Muestra$SECTOR
textos$Program.Level <- Muestra$`Academic Level`
View(textos)
textos$Accreditation <- Muestra$Accreditation
setwd("/home/jc/Documents/Paper Soft Skills Sampled Programs")
listado <- data.frame(dir())
library(readtext)
library(tm)
DirSource()
# Get the data directory from readtext
DATA_DIR <- system.file("extdata/", package = "readtext")
textos <- readtext(listado$dir..)
textos$doc_id <- gsub("[^0-9-]", "", textos$doc_id)
library(quanteda)
AllPrograms <- corpus(textos)
source("~/Documents/GitHub/SoftSkillsUniversityPrograms/SampleAnalysis.R")
docvars(AllPrograms, "Programa") <- Muestra$NOMBRE_DEL_PROGRAMA
docvars(AllPrograms, "Program.Level") <- Muestra$`Academic Level`
docvars(AllPrograms, "Institution") <- Muestra$NOMBRE_INSTITUCIÓN
SPEC <- corpus_subset(AllPrograms, Program.Level == "Specialization")
MS <- corpus_subset(AllPrograms, Program.Level == "Masters")
PhD <- corpus_subset(AllPrograms, Program.Level == "Doctorate")
spanishstopwords <- c("egresado", "programa", "programas", "crédito", stopwords("spanish"))
textos$Sector <- Muestra$SECTOR
textos$Program.Level <- Muestra$`Academic Level`
textos$Accreditation <- Muestra$Accreditation
# General Classification (All programs)
library(quanteda)
tokens <- textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 40, scheme = "docfreq")
dfm <- dfm_remove(dfm, c("así", "estudiantes", "área", "así"))
library(quanteda.textstats)
Programs <- textstat_simil(dfm, margin = "documents", method = "jaccard")
ProgramsDF <- data.frame(as.matrix(Programs))
ProgramsDF <- data.frame(jaccard = ProgramsDF[lower.tri(ProgramsDF, diag = FALSE)])
# In fourth place, we applied
# a Gaussian finite mixture model fitted by EM algorithm
library(mclust)
fit <- Mclust(ProgramsDF)
summary(fit)
Classification <- data.frame(fit$classification)
names(Classification)[1] <- "classification"
View(Classification)
View(textos)
# Public-Private Classification
tokens.O <- textos$text %>% filter(., Sector == "Official") %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
# Public-Private Classification
library(dplyr)
tokens.O <- textos$text %>% filter(., Sector == "Official") %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
tokens.O <- filter(textos, Sector == "Official") %>% textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
tokens.O <- textos$text %>% filter(., Sector == "Official")  %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
View(Officials)
OfficialP <- textos$text %>% filter(., Sector == "Official")
View(textos)
OfficialP <- textos %>% filter(., Sector == "Official")
tokens.O <- OfficialP$text  %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens.O), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 40, scheme = "docfreq")
dfm <- dfm_remove(dfm, c("así", "estudiantes", "área", "así"))
library(quanteda.textstats)
Programs <- textstat_simil(dfm, margin = "documents", method = "jaccard")
ProgramsDF <- data.frame(as.matrix(Programs))
ProgramsDF <- data.frame(jaccard = ProgramsDF[lower.tri(ProgramsDF, diag = FALSE)])
# In fourth place, we applied
# a Gaussian finite mixture model fitted by EM algorithm
library(mclust)
fit <- Mclust(ProgramsDF)
summary(fit)
Classification <- data.frame(fit$classification)
names(Classification)[1] <- "classification"
PrivateP <- textos %>% filter(., Sector == "Private")
tokens.P <- PrivateP$text  %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens.P), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 40, scheme = "docfreq")
dfm <- dfm_remove(dfm, c("así", "estudiantes", "área", "así"))
library(quanteda.textstats)
Programs <- textstat_simil(dfm, margin = "documents", method = "jaccard")
ProgramsDF <- data.frame(as.matrix(Programs))
ProgramsDF <- data.frame(jaccard = ProgramsDF[lower.tri(ProgramsDF, diag = FALSE)])
# In fourth place, we applied
# a Gaussian finite mixture model fitted by EM algorithm
library(mclust)
fit <- Mclust(ProgramsDF)
summary(fit)
load("~/Documents/GitHub/SoftSkillsUniversityPrograms/PreProcessing.RData")
rm(list=setdiff(ls(), "TODAS"))
Network <- TODAS[,c(1,5)]
table(Network$keyword)
verbos <- data.frame(table(Network$keyword))
View(TODAS)
setwd("/home/jc/Documents/Paper Soft Skills Sampled Programs")
listado <- data.frame(dir())
library(readtext)
library(tm)
DirSource()
# Get the data directory from readtext
DATA_DIR <- system.file("extdata/", package = "readtext")
textos <- readtext(listado$dir..)
textos$doc_id <- gsub("[^0-9-]", "", textos$doc_id)
library(quanteda)
AllPrograms <- corpus(textos)
source("~/Documents/GitHub/SoftSkillsUniversityPrograms/SampleAnalysis.R")
docvars(AllPrograms, "Programa") <- Muestra$NOMBRE_DEL_PROGRAMA
docvars(AllPrograms, "Program.Level") <- Muestra$`Academic Level`
docvars(AllPrograms, "Institution") <- Muestra$NOMBRE_INSTITUCIÓN
SPEC <- corpus_subset(AllPrograms, Program.Level == "Specialization")
MS <- corpus_subset(AllPrograms, Program.Level == "Masters")
PhD <- corpus_subset(AllPrograms, Program.Level == "Doctorate")
summary(AllPrograms)
aja <- data.frame(summary(AllPrograms, n = length(AllPrograms)))
Textos <- tokens(AllPrograms)
Textos <- tokens_tolower(Textos)
Textos
comunicar <- data.frame(kwic(Textos, pattern = "comunicar"))
crear <- data.frame(kwic(Textos, pattern = "crear"))
liderar <- data.frame(kwic(Textos, pattern = "liderar"))
resolver <- data.frame(kwic(Textos, pattern = "resolver"))
comprometer <- data.frame(kwic(Textos, pattern = "comprometer"))
comprometerse <- data.frame(kwic(Textos, pattern = "comprometerse"))
gestionar <- data.frame(kwic(Textos, pattern = "gestionar"))
reflexionar <- data.frame(kwic(Textos, pattern = "reflexionar"))
controlar <- data.frame(kwic(Textos, pattern = "controlar"))
etico <- data.frame(kwic(Textos, pattern = "ético"))
tolerar <- data.frame(kwic(Textos, pattern = "tolerar"))
argumentar <- data.frame(kwic(Textos, pattern = "argumentar"))
conflicto <- data.frame(kwic(Textos, pattern = "conflictos"))
negociar <- data.frame(kwic(Textos, pattern = "negociar"))
comprender <- data.frame(kwic(Textos, pattern = "comprender"))
equipo <- data.frame(kwic(Textos, pattern = "equipos"))
planificar <- data.frame(kwic(Textos, pattern = "planificar"))
generar <- data.frame(kwic(Textos, pattern = "generar"))
empatia <- data.frame(kwic(Textos, pattern = "empatía"))
compartir <- data.frame(kwic(Textos, pattern = "compartir"))
analizar <- data.frame(kwic(Textos, pattern = "analizar"))
reconocer <- data.frame(kwic(Textos, pattern = "reconocer"))
orientar <- data.frame(kwic(Textos, pattern = "orientar"))
respetar <- data.frame(kwic(Textos, pattern = "respetar"))
motivar <- data.frame(kwic(Textos, pattern = "motivar"))
cooperar <- data.frame(kwic(Textos, pattern = "cooperar"))
fortalecer <- data.frame(kwic(Textos, pattern = "fortalecer"))
impulsar <- data.frame(kwic(Textos, pattern = "impulsar"))
acercar <- data.frame(kwic(Textos, pattern = "acercar"))
ayudar <- data.frame(kwic(Textos, pattern = "ayudar"))
cambiar <- data.frame(kwic(Textos, pattern = "cambiar"))
apreciar <- data.frame(kwic(Textos, pattern = "apreciar"))
dirigir <- data.frame(kwic(Textos, pattern = "dirigir"))
fomentar <- data.frame(kwic(Textos, pattern = "fomentar"))
interactuar <- data.frame(kwic(Textos, pattern = "interactuar"))
identificar <- data.frame(kwic(Textos, pattern = "identificar"))
competir <- data.frame(kwic(Textos, pattern = "competir"))
manifestar <- data.frame(kwic(Textos, pattern = "manifestar"))
responsable <- data.frame(kwic(Textos, pattern = "responsable"))
evaluar <- data.frame(kwic(Textos, pattern = "evaluar"))
innovar <- data.frame(kwic(Textos, pattern = "innovar"))
rm(institution, LevelsOfficials, LevelsPrivate, listado, Muestra, Officials, Private, Sector, textos, Textos, DATA_DIR, veamos)
TODAS <- rbind(crear, innovar, acercar, analizar, apreciar, argumentar, ayudar, cambiar, compartir, competir,
comprender, comprometer, comprometerse, comunicar, conflicto, controlar, cooperar, dirigir,
empatia, equipo, etico, evaluar, fomentar, fortalecer, generar, gestionar, identificar, impulsar,
interactuar, liderar, manifestar, motivar, negociar, orientar, planificar, reconocer, reflexionar,
resolver, respetar, responsable, tolerar)
colnames(aja)[1]  <- "docname"
library(dplyr)
TODAS2 <- TODAS %>% select(-from, -to, -pre, -post, -pattern) %>% left_join(aja, by = "docname")
View(TODAS2)
Spec <- TODAS2 %>% filter(., Program.Level == "Specialization")
MS <- TODAS2 %>% filter(., Program.Level == "Masters")
PhD <- TODAS2 %>% filter(., Program.Level == "Doctorate")
Spec <- Spec %>% select(., "docname", "keyword")
MS <- MS %>% select(., "docname", "keyword")
PhD <- PhD %>% select(., "docname", "keyword")
View(PhD)
save.image("~/Documents/GitHub/SoftSkillsUniversityPrograms/PreProcessing.RData")
load("~/Documents/GitHub/SoftSkillsUniversityPrograms/PreProcessing.RData")
rm(list=setdiff(ls(), "Spec"))
bn2 <- graph.data.frame(Spec,directed=FALSE)
bipartite.mapping(bn2)
V(bn2)$type <- bipartite_mapping(bn2)$type
V(bn2)$color <- ifelse(V(bn2)$type, "red", "green")
V(bn2)$shape <- ifelse(V(bn2)$type, "circle", "square")
#V(bn2)$label.cex <- ifelse(V(bn2)$type, 0.8, 1)
V(bn2)$size <- 3.5
E(bn2)$color <- "grey"
plot(bn2,
vertex.label = NA,
layout = layout_nicely,
main = "")
summary(bn2)
V(bn2)$name[1:10]
table(V(bn2)$type)
V(bn2)$color[1:10]
V(bn2)$shape[1:10]
# Network node prominence measures
prominence <- data.frame(betweenness(bn2))
prominence2 <- data.frame(degree(bn2))
prominence3 <- data.frame(bonpow(bn2))
prominence4 <- page.rank(bn2)
prominence4 <- data.frame(prominence4$vector)
prominence4$Program <- rownames(prominence4)
prominence5 <- data.frame(eigen_centrality(bn2))
library(dplyr)
HighestSkills <- prominence4 %>% filter(., prominence4$prominence4.vector > 0.0037)
View(HighestSkills)
HighestSkills$Program[69]
HS <- HighestSkills[69:93,]
View(HS)
bn2 <- graph.data.frame(Spec,directed=FALSE)
bipartite.mapping(bn2)
V(bn2)$type <- bipartite_mapping(bn2)$type
V(bn2)$color <- ifelse(V(bn2)$type, "red", "green")
V(bn2)$shape <- ifelse(V(bn2)$type, "circle", "square")
V(bn2)$label.cex <- ifelse(V(bn2)$type, 0.8, 1)
V(bn2)$size <- sqrt(degree(bn2))
E(bn2)$color <- "grey"
plot(bn2,
vertex.label = NA,
layout = layout_components,
main = "")
table(degree(bn2,v=V(bn2)[type==FALSE]))
mean(degree(bn2,v=V(bn2)[type==FALSE]))
var(degree(bn2,v=V(bn2)[type==FALSE]))
min(degree(bn2,v=V(bn2)[type==FALSE]))
max(degree(bn2,v=V(bn2)[type==FALSE]))
V(bn2)$deg <- degree(bn2)
V(bn2)[type==FALSE & deg > 4]$name
RelevantPrograms <- data.frame(cbind(
Program = V(bn2)[type == FALSE]$name,
Skills = V(bn2)[type==FALSE & deg >= 4]$deg))
View(RelevantPrograms)
93/115
RelevantPrograms$Skills <- as.numeric(RelevantPrograms$Skills)
ah <- data.frame(table(RelevantPrograms$Skills))
colnames(ah)[1] <- "degree"
ah$degree <- as.numeric(ah$degree)
plot(ah$degree, ah$Freq, xlab = "degree", ylab= "Frequency")
hist(RelevantPrograms$Skills, xlab= "Skills per program", main = "")
bn2.pr <- bipartite.projection(bn2)
Programs <- bn2.pr$proj1
Terms <- bn2.pr$proj2
c1 = cluster_fast_greedy(Terms)
c2 = cluster_fast_greedy(Terms)
# modularity measure
modularity(c1)
B = modularity_matrix(Programs, membership(c1))
round(B[1,],2)
membership(c1)
length(c1)
sizes(c1)
crossing(c1, Terms)
plot(c1, Terms, layout=layout_nicely(Terms, dim = 2))
clique.number(Terms)
largest_cliques(Terms)
library(intergraph)
graph.coreness(Terms)
coreness <- graph.coreness(Terms)
table(coreness)
V(Terms)$color <- coreness + 1
plot(Terms,vertex.label.cex=0.8, layout = layout_components)
cluster_fast_greedy(Terms)
cluster_louvain(Terms)
cluster_spinglass(Terms)
oye <- cluster_leading_eigen(Terms)
oye2 <- cluster_leading_eigen(Programs)
modularity(oye)
modularity(oye2)
plot_dendrogram(oye)
plot_dendrogram(oye2)
modularity(c2)
B2 = modularity_matrix(Terms, membership(c2))
round(B2[1,],2)
membership(c2)
length(c2)
sizes(c2)
crossing(c2, Terms)
plot(c2, Terms, layout=layout_with_dh)
plot(Terms, vertex.color=membership(c2), layout=layout_with_dh)
graph.density(Programs)
CentralityPrograms <- data.frame(degree(Programs))
graph.density(Terms)
get.adjacency(Programs)
T2 <- as.matrix(get.adjacency(Terms)  )
summary(bn2)
summary(Programs)
graph.density(bn2)
graph.density(Programs)
graph.density(Terms)
components(Programs)
hum <- data.frame(degree(bn2))
View(hum)
degree_distribution(bn2)
hist(degree_distribution(bn2))
ecount(bn2) #size of the graph (number of edges)
edge.betweenness(bn2)
hist(edge.betweenness(bn2))
EB <- data.frame(edge.betweenness(bn2))
edge.connectivity(bn2)
edge.connectivity(bn2)
SN <- as.matrix(get.adjacency(bn2))
SN1 <- as.data.frame(SN)
Skills <- as.data.frame(get.incidence(bn2))
View(Skills)
setwd("/home/jc/Documents/Paper Soft Skills Sampled Programs")
listado <- data.frame(dir())
library(readtext)
library(tm)
DirSource()
# Get the data directory from readtext
DATA_DIR <- system.file("extdata/", package = "readtext")
textos <- readtext(listado$dir..)
textos$doc_id <- gsub("[^0-9-]", "", textos$doc_id)
library(quanteda)
AllPrograms <- corpus(textos)
source("~/Documents/GitHub/SoftSkillsUniversityPrograms/SampleAnalysis.R")
docvars(AllPrograms, "Programa") <- Muestra$NOMBRE_DEL_PROGRAMA
docvars(AllPrograms, "Program.Level") <- Muestra$`Academic Level`
docvars(AllPrograms, "Institution") <- Muestra$NOMBRE_INSTITUCIÓN
SPEC <- corpus_subset(AllPrograms, Program.Level == "Specialization")
MS <- corpus_subset(AllPrograms, Program.Level == "Masters")
PhD <- corpus_subset(AllPrograms, Program.Level == "Doctorate")
spanishstopwords <- c("egresado", "programa", "programas", "crédito", stopwords("spanish"))
textos$Sector <- Muestra$SECTOR
textos$Program.Level <- Muestra$`Academic Level`
textos$Accreditation <- Muestra$Accreditation
# General Classification (All programs)
library(quanteda)
tokens <- textos$text %>%
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(c("campo", "través", "maestría", "país", "áreas", "nivel", "calidad", "estudios", "universidad", "profesionales", "perfil", "profesional", "especialización", "nacional", "formación", "egresado", "programa", "programas", "crédito", stopwords("spanish")))
dfm <- dfm_trim(dfm(tokens), min_docfreq = 0.005, max_docfreq = 0.99,
docfreq_type = "prop", verbose = TRUE)
topfeatures(dfm, n = 40, scheme = "docfreq")
dfm <- dfm_remove(dfm, c("así", "estudiantes", "área", "así"))
library(quanteda.textstats)
Programs <- textstat_simil(dfm, margin = "documents", method = "jaccard")
ProgramsDF <- data.frame(as.matrix(Programs))
ProgramsDF <- data.frame(jaccard = ProgramsDF[lower.tri(ProgramsDF, diag = FALSE)])
# In fourth place, we applied
# a Gaussian finite mixture model fitted by EM algorithm
library(mclust)
fit <- Mclust(ProgramsDF)
summary(fit)
Classification <- data.frame(fit$classification)
View(Classification)
